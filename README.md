# Splunk

<h1>Log Analysis with Splunk</h1>
<body>Completed this analysis with help of Try Hack Me.</body></br>
<body>Room info : Splunk Basics - Did you SIEM?</body></br>
Room Type:
Free Room.Anyone can deploy virtual machines in the room


<h2>Description</h2>
Project consists of
Ingest and interpret custom log data in Splunk
Create and apply custom field extractions
Use Search Processing Language (SPL) to filter and refine search results
Conduct an investigation within Splunk to uncover key insights like,

- Exploring the Logs
- Initial Triage
- Visualizing the Logs Timeline
- Anomaly Detection
- Filtering out Benign Values
- Narrowing Down Suspicious IPs
- Tracing the Attack Chain
- Exfiltration Attempts
- Ransomware Staging & RCE
- Correlate Outbound C2 Communication
- Volume of Data Exfiltrated

<h2>Languages and Utilities Used</h2>

- <b>Search Processing Language (SPL)</b> 
- <b>Virtual Machines deployed in Try Hack Me</b>

<h2>Environments Used </h2>

- <b>Windows 11</b> 

<h2>Program walk-through:</h2>

<p align="left">
<b>Exploring the Logs:</b> <br/>
The data has already been ingested into the Splunk instance for analysis. To begin investigating the incident, open the Splunk interface and click Search & Reporting from the left-hand panel, as shown below.
<br />
<br />
<img width="1364" height="792" alt="Image" src="https://github.com/user-attachments/assets/b8c7ea1e-222d-414a-86ad-0c968bf436a1" />
<br />
<br />
On the next page, enter index=main in the search bar to display all the ingested logs.
<br />
<br />
<img width="1919" height="1199" alt="2" src="https://github.com/user-attachments/assets/1926c562-29bf-455c-a549-f0edda7ab08d" />
The investigation involves two primary datasets:<br />
  
- <b>web_traffic:</b> Contains events related to incoming and outgoing web connections associated with the web server.<br />
  
- <b>firewall_logs:</b> Includes firewall records that indicate whether network traffic was allowed or blocked.<br />
The web server is assigned the local IP address 10.10.1.15.
---------------------------------------------------------------------------------------------------------------------------------
<br />
<b>Initial Triage:</b> <br />
Begin by running a basic search on the index using the custom source type web_traffic. In the search bar, enter the following query:

<b>Search Query:</b> index=main sourcetype=web_traffic
<br />
<br />
<img width="1919" height="1199" alt="3" src="https://github.com/user-attachments/assets/0d22a7ae-c84a-48a7-954f-79b4ac2237f7" />
<br />
<br />
Let’s break down the results to better understand what we’re seeing in Splunk:

<b>Search query:</b> This query pulls all events from the main index that are tagged with the custom source type web_traffic. It serves as the starting point for our investigation and ensures we’re working with the correct dataset.

<b>Time range:</b> The search is currently set to All time, allowing us to view the complete dataset. During an actual security investigation, this range would typically be narrowed down later such as focusing on the specific time window where abnormal activity or traffic spikes were observed.

<b>Timeline:</b> The histogram visualizes how the 17,172 events are distributed over time. It shows normal daily log activity followed by a noticeable spike in traffic, which likely corresponds to the potential attack window.

<b>Selected fields:</b> These are the fields currently displayed in the event list summary (such as host, source, and sourcetype). They provide basic metadata about where the logs originated and how they were ingested.

<b>Interesting fields:</b> This panel displays all fields that Splunk has either automatically extracted or manually defined. Fields prefixed with # (for example, #date_hour) are automatically generated by Splunk’s time-based commands. The presence of fields like user_agent, path, and client_ip confirms that the web logs have been parsed correctly.

<b>Event details & field extraction:</b> This section shows the detailed breakdown of an individual event, including extracted fields such as user_agent, path, status, client_ip, and others. These fields will be critical for identifying suspicious behavior during the investigation.

Now that we have a solid understanding of the Splunk interface and how to interpret the logs, we can move forward with a deeper analysis of the dataset.

---------------------------------------------------------------------------------------------------------------------------------
<br />
<b>Visualizing the Logs Timeline:</b> <br />
Next, we’ll visualize the total number of events over time, grouped by day. This will allow us to see the daily event volume and quickly identify any day that experienced an unusually high number of logs, which may indicate abnormal or malicious activity.
<br />
<br />
<b>Search query:</b> index=main sourcetype=web_traffic | timechart span=1d count
<br />
<br />
<img width="1919" height="1199" alt="4" src="https://github.com/user-attachments/assets/9d5d21f0-36a8-425e-8cf5-c7ae74f2a6f8" />
<br />
The results above now display the number of events captured on a daily basis. This is particularly interesting, as we can observe that certain days have a noticeably higher volume of logs than others. To get a clearer and more intuitive view of this pattern, we can switch to the Visualization tab and examine the graph, as shown below.
<br />
<br />
<img width="1919" height="1199" alt="5" src="https://github.com/user-attachments/assets/e1b74fc4-fb62-4b14-9bb7-9c3b76209ad5" />
<br />
<br />
We can append the reverse function to the end of the query to sort the results in descending order. This places the day with the highest number of events at the top, making it easier to quickly identify periods of unusually high activity.
<br/>
<br/>
<b>Search query:</b>index=main sourcetype=web_traffic | timechart span=1d count | sort by count | reverse 
<br />
<br />
<img width="1919" height="1199" alt="7" src="https://github.com/user-attachments/assets/b718db0d-322c-4726-9ee0-9f04124971d0" />

---------------------------------------------------------------------------------------------------------------------------------
<br />
<b>Anomaly Detection:</b><br /><br />
Now that we’ve identified the days with unusually high log activity using both the table and the visualization, we can continue our investigation by examining specific fields for suspicious values. To do this, we’ll return to the Events tab and use the same search query to dig deeper into the data.
<b>User Agent</b>
Let's click on the user_agent field in the left panel, as shown below. It will show us the details about the user agents captured so far. 
<br/>
<br/>
<img width="1919" height="1199" alt="8" src="https://github.com/user-attachments/assets/9e94116e-faf0-4763-b2f4-7085012b3104" />
<br/>
<br/>
Upon closer inspection, we can see that alongside legitimate user agents such as standard Mozilla variants there is a significant number of suspicious user agents present in the logs. These anomalous entries warrant further investigation to determine whether they are associated with malicious or automated activity.
<br />
<br />
<b>client_ip</b><br/><br/>
The second field we will examine is the client_ip, which contains the IP addresses of the clients accessing the web server. We can immediately see one particular IP address standing out, which we will investigate further.
<br/>
<br/>
<img width="1919" height="1199" alt="9" src="https://github.com/user-attachments/assets/6cd72648-798d-40fa-977b-2b1db9ccab02" />
<br/>
<br/>
<b>path</b>
<br/>
<br/>
The third field we will examine is path, which contains the URI being requested and accessed by the client IPs. The results shown below clearly indicate some attacks worth investigating.
<br/><br/>
<img width="1919" height="1199" alt="10" src="https://github.com/user-attachments/assets/c44f727f-630e-430f-9ea2-98691c15baec" />

---------------------------------------------------------------------------------------------------------------------------------
<br/>
<b>Filtering out Benign Values:</b>
<br/>
<br/>
To focus our analysis on potentially malicious activity, let’s filter out standard, legitimate traffic. By excluding commonly seen user agents, the following query removes normal user behavior from the results and highlights only the suspicious user agents that require further investigation.
<br/>
<br/>
<b>Search query:</b> index=main sourcetype=web_traffic user_agent!=*Mozilla* user_agent!=*Chrome* user_agent!=*Safari* user_agent!=*Firefox*
<br/>
<br/>
<img width="1919" height="1199" alt="11" src="https://github.com/user-attachments/assets/8b568588-2b85-4fe2-bf6b-91f6d4b9bb97" />
<br/>
<br/>
The output reveals some noteworthy findings. By drilling down into the client_ip field, we can see that a single IP address is responsible for all the suspicious user agents. We’ll take note of this IP address and use it to replace the <REDACTED> values in the upcoming queries as we continue the investigation.

---------------------------------------------------------------------------------------------------------------------------------
<br/>
<b>Narrowing Down Suspicious IPs</b>
<br/>
<br/>
In real-world environments, servers are frequently targeted by numerous IP addresses attempting to carry out attacks. To better focus our analysis, we can narrow the results to IPs that are not generating traffic from common desktop or mobile browsers by using the following query.
<br/>
<br/>
<b>Search query:</b> sourcetype=web_traffic user_agent!=*Mozilla* user_agent!=*Chrome* user_agent!=*Safari* user_agent!=*Firefox* | stats count by client_ip | sort -count | head 5
<br/>
<br/>
<img width="1919" height="637" alt="12" src="https://github.com/user-attachments/assets/ece2e9bf-d781-4832-aeba-7845a741f2b4" />
<br/>
<br/>
In the search query, the minus sign (-) in the sort -count command sorts the results in descending order, which is equivalent to using the reverse function. We can now select this IP address and apply a filter to examine the activity footprints it has left behind in the logs.

---------------------------------------------------------------------------------------------------------------------------------
<br/>
<b>Tracing the Attack Chain</b>
<br/>
<br/>
We will now focus on the identified attacker IP to trace its activity chronologically and reconstruct the sequence of actions taken. This will help confirm the use of multiple tools and payloads during the attack.
<br/>
<br/>
<b>Reconnaissance (Footprinting)</b>
<br/>
<br/>
We will start searching for the initial probing of exposed configuration files using the query below:
<br/>
<br/>
<b>Search query:</b> sourcetype=web_traffic client_ip="198.51.100.55" AND path IN ("/.env", "/*phpinfo*", "/.git*") | table _time, path, user_agent, status
<br/>
<br/>
<img width="1919" height="1199" alt="13" src="https://github.com/user-attachments/assets/fcaa079e-bdf8-49a3-ada2-a55abfe430a8" />
<br/>
The result confirms the attacker used low-level tools (curl, wget) and was met with 404/403/401 status codes.
<br/>
<br/>
<b>Enumeration (Vulnerability Testing)</b>
<br/>
<br/>
Search for common path traversal and open redirect vulnerabilities.
<br/>
<br/>
<b>Search query: </b>sourcetype=web_traffic client_ip="198.51.100.55" AND path="*..*" OR path="*redirect*"
<br/>
<br/>
<img width="1919" height="1199" alt="14" src="https://github.com/user-attachments/assets/669bff99-b25d-4053-8baa-112812be1eb1" />
<br/>
<br/>
The output shows the resources the attacker is trying to access. Let's update the search query to get the count of the resources requested by the attacker. This search query is filtering on the paths that contain either ../../ or the term redirect in it, as shown below. This is done to look for footprints of path traversal attempts (../../). To, we need to update in the search query to escape the characters like ..\/..\/.
<br/>
<br/>
<b>Search query:</b> sourcetype=web_traffic client_ip="198.51.100.55" AND path="*..\/..\/*" OR path="*redirect*" | stats count by path
<br/>
<br/>
<img width="1919" height="593" alt="15" src="https://github.com/user-attachments/assets/a02953aa-09c3-41c7-a184-58a782995f76" />
<br/>
Quite interesting results. Reveals attempts to read system files (../../*), showing the attacker moved beyond simple scanning to active vulnerability testing.
<br/>
<br/>
<b>SQL Injection Attack</b>
<br/>
<br/>
Find the automated attack tool and its payload by using the query below:
<br/>
<br/>
<b>Search query:</b> sourcetype=web_traffic client_ip="198.51.100.55" AND user_agent IN ("*sqlmap*", "*Havij*") | table _time, path, status
<br/>
<br/>
<img width="1919" height="902" alt="16" src="https://github.com/user-attachments/assets/4cbdd215-100a-4cf1-aa75-9a3a1ce4df90" />
</br>
Above results confirms the use of known SQL injection and specific attack strings like SLEEP(5). A 504 status code often confirms a successful time-based SQL injection attack.

---------------------------------------------------------------------------------------------------------------------------------
<br/>
<b>Exfiltration Attempts</b>
<br/>
<br/>
Search for attempts to download large, sensitive files (backups, logs). We can use the query below:
<br/>
<br/>
<b>Search query:</b> sourcetype=web_traffic client_ip="198.51.100.55" AND path IN ("*backup.zip*", "*logs.tar.gz*") | table _time path, user_agent
<br/>
<br/>
<img width="1919" height="1199" alt="17" src="https://github.com/user-attachments/assets/4572be8c-bcdf-4c68-945c-4408f73c2ac1" />
<br/>
The results indicate the attacker was exfiltrating large chunks of compressed log files using tools like curl, zgrab, and more. We can confirm the details about these connections in the firewall logs.

---------------------------------------------------------------------------------------------------------------------------------
<br/>
<b>Ransomware Staging & RCE</b>
<br/>
<br/>
Requests for sensitive resources such as /logs.tar.gz and /config suggest that the attacker is attempting to collect data, a common tactic used in double-extortion attacks. Additionally, the logs show several requests referencing bunnylock and shell.php, which are strong indicators of malicious activity. To better understand these requests and their intent, we’ll use the following query to examine them in more detail.
<br/>
<br/>
<b>Search query:</b> sourcetype=web_traffic client_ip="198.51.100.55" AND path IN ("*bunnylock.bin*", "*shell.php?cmd=*") | table _time, path, user_agent, status
<br/>
<br/>
<img width="1919" height="1199" alt="18" src="https://github.com/user-attachments/assets/141d29a2-4b03-4ca2-8271-34914c1acb59" />
<br/>
The results clearly confirm the presence of a successful web shell. This indicates that the attacker has gained full control over the web server and is able to execute commands remotely. Such an attack is classified as Remote Code Execution (RCE).

Additionally, the execution of /shell.php?cmd=./bunnylock.bin strongly suggests that a ransomware-like payload was run on the server, further confirming the severity of the compromise.

---------------------------------------------------------------------------------------------------------------------------------
<br/>
<b>Correlate Outbound C2 Communication</b>
<br/>
<br/>
Next, we pivot our analysis to the firewall_logs dataset, using the compromised server IP address (10.10.1.5) as the source and the attacker’s IP address as the destination. This allows us to examine how the firewall handled the traffic between the compromised host and the attacker.
<br/>
<br/>
<b>Search query:</b> sourcetype=firewall_logs src_ip="10.10.1.5" AND dest_ip="198.51.100.55" AND action="ALLOWED" | table _time, action, protocol, src_ip, dest_ip, dest_port, reason
<br/>
<br/>
<img width="1919" height="1199" alt="19" src="https://github.com/user-attachments/assets/e64c5c05-d060-479a-bcc3-2c6a7126612b" />
<br/>
This query proves the server immediately established an outbound connection to the attacker's C2 IP on the suspicious DEST_PORT. The ACTION=ALLOWED and REASON=C2_CONTACT fields confirm the malware communication channel was active.

---------------------------------------------------------------------------------------------------------------------------------
<br/>
<b>Volume of Data Exfiltrated</b>
<br/>
<br/>
We can also use the sum function to calculate the sum of the bytes transferred, using the bytes_transferred field, as shown below:
<br/>
<br/>
<b>Search Query:</b> sourcetype=firewall_logs src_ip="10.10.1.5" AND dest_ip="<REDACTED>" AND action="ALLOWED" | stats sum(bytes_transferred) by src_ip
<br/>
<br/>
<img width="1919" height="530" alt="20" src="https://github.com/user-attachments/assets/e2b2aa50-ebe1-4466-be71-780a5aa9d347" />
<br/>
The results show a hugh volume of data transferred from the compromised webserver to C2 server.

---------------------------------------------------------------------------------------------------------------------------------
<br/>

<b>Conclusion</b>
<br/>
<br/>
<b>Identity found:</b>The attacker was identified via the highest volume of malicious web traffic originating from the external IP.
<br/>
<b>Intrusion vector:</b> The attack followed a clear progression in the web logs (sourcetype=web_traffic).
<br/>
<b>Reconnaissance:</b> Probes were initiated via cURL/Wget, looking for configuration files (/.env) and testing path traversal vulnerabilities.
<br/>
<b>Exploitation:</b> The use of SQLmap user agents and specific payloads (SLEEP(5)) confirmed the successful exploitation phase.
</br>
<b>Payload delivery:</b> The Action on Objective was established by the final successful execution of the command cmd=./bunnylock.bin via the webshell.
<br/>
<b>C2 confirmation:</b> The pivot to the firewall logs (sourcetype=firewall_logs) proved the post-exploitation activity. The internal, compromised server (SRC_IP: 10.10.1.5) established an outbound C2 connection to the attacker's IP.
<br/>
</p>

---------------------------------------------------------------------------------------------------------------------------------


<!--
 ```diff
- text in red
+ text in green
! text in orange
# text in gray
@@ text in purple (and bold)@@
```
--!>
